Here's how you can refactor the `integrity_check` package to make it more unit-testable:

## 1. Create Core Interfaces and Abstractions

```python
# interfaces.py
from abc import ABC, abstractmethod
from typing import Dict, Set, Tuple, Optional, Any
from pathlib import Path

class FileSystemInterface(ABC):
    """Abstract interface for file system operations"""

    @abstractmethod
    def exists(self, path: str) -> bool:
        pass

    @abstractmethod
    def is_file(self, path: str) -> bool:
        pass

    @abstractmethod
    def is_dir(self, path: str) -> bool:
        pass

    @abstractmethod
    def walk(self, path: str):
        pass

    @abstractmethod
    def read_file_chunks(self, path: str, chunk_size: int = 65536):
        pass

    @abstractmethod
    def readlink(self, path: str) -> str:
        pass

class HashStorageInterface(ABC):
    """Abstract interface for hash storage operations"""

    @abstractmethod
    def put_hashtable(self, hash_info: Dict[str, Any]) -> Dict[str, Set[str]]:
        pass

    @abstractmethod
    def get_hashtable(self, path: str) -> Optional[Dict[str, Any]]:
        pass

    @abstractmethod
    def get_single_hash(self, path: str) -> Optional[str]:
        pass

class TimeProvider(ABC):
    """Abstract interface for time operations"""

    @abstractmethod
    def current_time(self) -> float:
        pass

class HashFunction(ABC):
    """Abstract interface for hash operations"""

    @abstractmethod
    def create_hasher(self):
        pass

    @abstractmethod
    def hash_string(self, data: str) -> str:
        pass
```

## 2. Create Concrete Implementations

```python
# implementations.py
import hashlib
from time import time
from pathlib import Path
from typing import Dict, Set, Any, Optional
from .interfaces import FileSystemInterface, HashStorageInterface, TimeProvider, HashFunction

class StandardFileSystem(FileSystemInterface):
    """Standard file system implementation using pathlib"""

    def exists(self, path: str) -> bool:
        return Path(path).exists()

    def is_file(self, path: str) -> bool:
        return Path(path).is_file()

    def is_dir(self, path: str) -> bool:
        return Path(path).is_dir()

    def walk(self, path: str):
        return Path(path).walk()

    def read_file_chunks(self, path: str, chunk_size: int = 65536):
        with open(path, 'rb') as f:
            while True:
                data = f.read(chunk_size)
                if not data:
                    break
                yield data

    def readlink(self, path: str) -> str:
        return str(Path(path).readlink())

class RestHashStorage(HashStorageInterface):
    """Hash storage implementation using REST connector"""

    def __init__(self, rest_connector):
        self.rest_connector = rest_connector

    def put_hashtable(self, hash_info: Dict[str, Any]) -> Dict[str, Set[str]]:
        return self.rest_connector.put_hashtable(hash_info)

    def get_hashtable(self, path: str) -> Optional[Dict[str, Any]]:
        return self.rest_connector.get_hashtable(path)

    def get_single_hash(self, path: str) -> Optional[str]:
        return self.rest_connector.get_single_hash(path)

class SystemTimeProvider(TimeProvider):
    """System time provider implementation"""

    def current_time(self) -> float:
        return time()

class SHA1HashFunction(HashFunction):
    """SHA-1 hash function implementation"""

    def create_hasher(self):
        return hashlib.sha1()

    def hash_string(self, data: str) -> str:
        return hashlib.sha1(data.encode()).hexdigest()
```

## 3. Create a Path Validator

```python
# validators.py
from pathlib import Path

class PathValidator:
    """Validates path operations for integrity checking"""

    def validate_root_and_dir_paths(self, root_path: str, dir_path: str) -> bool:
        """Validate that dir_path is within root_path"""
        try:
            root = Path(root_path).resolve()
            target = Path(dir_path).resolve()
            return str(target).startswith(str(root))
        except (OSError, ValueError):
            return False

    def validate_path_exists(self, path: str) -> bool:
        """Validate that path exists"""
        return Path(path).exists()
```

## 4. Create Directory Tree Walker

```python
# tree_walker.py
from typing import Dict, List
from .interfaces import FileSystemInterface

class DirectoryTreeWalker:
    """Handles directory tree traversal and categorization"""

    def __init__(self, file_system: FileSystemInterface):
        self.file_system = file_system

    def get_tree_structure(self, parent_path: str) -> Dict[str, Dict[str, List[str]]]:
        """
        Recursively traverse directory tree and categorize items

        Args:
            parent_path: Root directory path to begin traversal

        Returns:
            Dictionary mapping directory paths to their contents
        """
        tree_dict = {}

        for item in self.file_system.walk(parent_path):
            dir_path, item_dirs, item_files = item

            # Separate files from links
            clean_files, clean_links = self._categorize_files(dir_path, item_files)

            tree_dict[str(dir_path)] = {
                "dirs": sorted([str(item) for item in item_dirs]),
                "files": sorted(clean_files),
                "links": sorted(clean_links)
            }

        return tree_dict

    def _categorize_files(self, dir_path, item_files):
        """Separate regular files from links"""
        clean_files, clean_links = [], []

        for item in item_files:
            full_path = str(dir_path / item)
            if self.file_system.is_file(full_path):
                clean_files.append(item)
            else:
                clean_links.append(item)

        return clean_files, clean_links
```

## 5. Create File Hasher

```python
# file_hasher.py
from typing import Dict, Any
from .interfaces import FileSystemInterface, HashFunction, TimeProvider

class FileHasher:
    """Handles hashing of files, directories, and links"""

    def __init__(self, file_system: FileSystemInterface, hash_function: HashFunction, time_provider: TimeProvider):
        self.file_system = file_system
        self.hash_function = hash_function
        self.time_provider = time_provider

    def hash_file(self, file_path: str) -> str:
        """Hash a regular file by reading its contents"""
        hasher = self.hash_function.create_hasher()

        for chunk in self.file_system.read_file_chunks(file_path):
            hasher.update(chunk)

        return hasher.hexdigest()

    def hash_link(self, link_path: str) -> str:
        """Hash a symbolic link by its path and target"""
        link_representation = self._get_link_representation(link_path)
        return self.hash_function.hash_string(link_representation)

    def hash_directory(self, dir_path: str, hash_info: Dict[str, Any]) -> str:
        """Hash a directory based on its contents"""
        dir_representation = self._get_directory_representation(dir_path, hash_info)
        return self.hash_function.hash_string(dir_representation)

    def _get_link_representation(self, link_path: str) -> str:
        """Get string representation of a link for hashing"""
        target = self.file_system.readlink(link_path)
        return f"{link_path} -> {target}"

    def _get_directory_representation(self, dir_path: str, hash_info: Dict[str, Any]) -> str:
        """Get string representation of directory contents for hashing"""
        hash_string = ''

        for category in ['dirs', 'files', 'links']:
            items = hash_info[dir_path].get(category, [])
            if items:
                for item in sorted(items):
                    item_path = f"{dir_path}/{item}"
                    hash_string += hash_info[item_path]['current_hash']
            else:
                hash_string += f"{dir_path}/{category}: EMPTY "

        return hash_string

    def get_current_timestamp(self) -> str:
        """Get current timestamp as string"""
        return str(self.time_provider.current_time())
```

## 6. Create Main Merkle Tree Service

```python
# merkle_tree_service.py
from typing import Dict, Set, Tuple, Optional, Any
from .interfaces import HashStorageInterface
from .validators import PathValidator
from .tree_walker import DirectoryTreeWalker
from .file_hasher import FileHasher

class MerkleTreeService:
    """Main service for Merkle tree integrity checking"""

    def __init__(self,
                 hash_storage: HashStorageInterface,
                 tree_walker: DirectoryTreeWalker,
                 file_hasher: FileHasher,
                 path_validator: PathValidator):
        self.hash_storage = hash_storage
        self.tree_walker = tree_walker
        self.file_hasher = file_hasher
        self.path_validator = path_validator

    def compute_merkle_tree(self, root_path: str, dir_path: str) -> Tuple[Optional[str], Optional[Dict[str, Set[str]]]]:
        """
        Create a Merkle tree hash for a directory and detect changes

        Args:
            root_path: Root directory of the monitored tree
            dir_path: Directory to hash (must be within root_path)

        Returns:
            Tuple of (directory_hash, changes_dict) or (None, None) if invalid
        """
        # Validate paths
        if not self.path_validator.validate_root_and_dir_paths(root_path, dir_path):
            print(f"ERROR: Requested path is not a child of the given root_path")
            return None, None

        # Initialize change tracking
        changes = {'Created': set(), 'Deleted': set(), 'Modified': set()}

        # Get directory tree structure
        tree_dict = self.tree_walker.get_tree_structure(dir_path)

        # Compute Merkle tree hash
        dir_hash = self._compute_merkle_recursive(dir_path, changes, tree_dict)

        # Update parent hashes if necessary
        if root_path != dir_path:
            self._recompute_parent_hashes(root_path, dir_path, changes)

        return dir_hash, changes

    def _compute_merkle_recursive(self, dir_path: str, changes: Dict[str, Set[str]], tree_dict: Dict[str, Any]) -> str:
        """Recursively compute Merkle tree hashes"""
        # Initialize hash info for this directory
        hash_info = {dir_path: {}}

        # Add directory structure to hash info
        for category in ['dirs', 'files', 'links']:
            hash_info[dir_path][category] = tree_dict[dir_path][category]

            # Initialize hash info for each item
            for item in tree_dict[dir_path][category]:
                item_path = f"{dir_path}/{item}"
                hash_info[item_path] = {}

        # Hash subdirectories recursively
        for item in tree_dict[dir_path]['dirs']:
            item_path = f"{dir_path}/{item}"
            hash_info[item_path]["current_hash"] = self._compute_merkle_recursive(item_path, changes, tree_dict)
            hash_info[item_path]["current_dtg_latest"] = self.file_hasher.get_current_timestamp()

        # Hash links
        for item in tree_dict[dir_path]['links']:
            item_path = f"{dir_path}/{item}"
            hash_info[item_path]["current_hash"] = self.file_hasher.hash_link(item_path)
            hash_info[item_path]["current_dtg_latest"] = self.file_hasher.get_current_timestamp()

        # Hash files
        for item in tree_dict[dir_path]['files']:
            item_path = f"{dir_path}/{item}"
            hash_info[item_path]["current_hash"] = self.file_hasher.hash_file(item_path)
            hash_info[item_path]["current_dtg_latest"] = self.file_hasher.get_current_timestamp()

        # Hash the directory itself and update changes
        self._update_directory_hash(hash_info, dir_path, changes)

        return hash_info[dir_path]["current_hash"]

    def _update_directory_hash(self, hash_info: Dict[str, Any], dir_path: str, changes: Dict[str, Set[str]]):
        """Update directory hash and track changes"""
        # Compute directory hash
        hash_info[dir_path]['current_hash'] = self.file_hasher.hash_directory(dir_path, hash_info)
        hash_info[dir_path]['current_dtg_latest'] = self.file_hasher.get_current_timestamp()

        # Store hash info and get changes
        detected_changes = self.hash_storage.put_hashtable(hash_info)

        # Merge changes
        for category in changes.keys():
            changes[category].update(detected_changes[category])

    def _recompute_parent_hashes(self, root_path: str, dir_path: str, changes: Dict[str, Set[str]]):
        """Recompute parent directory hashes up to root"""
        current_path = dir_path

        while current_path != root_path:
            # Move to parent directory
            current_path = current_path.rsplit('/', 1)[0]

            # Get existing hash info for parent
            parent_info = self.hash_storage.get_hashtable(current_path)
            if not parent_info:
                continue

            # Build hash info for parent
            hash_info = {current_path: parent_info}

            # Get hashes for all children
            for category in ['dirs', 'files', 'links']:
                for item in parent_info[category]:
                    item_hash = self.hash_storage.get_single_hash(item)
                    if item_hash:
                        hash_info[item] = {'current_hash': item_hash}

            # Update parent hash
            self._update_directory_hash(hash_info, current_path, changes)
```

## 7. Create Factory for Easy Setup

```python
# factory.py
from .merkle_tree_service import MerkleTreeService
from .implementations import StandardFileSystem, RestHashStorage, SystemTimeProvider, SHA1HashFunction
from .validators import PathValidator
from .tree_walker import DirectoryTreeWalker
from .file_hasher import FileHasher

class IntegrityCheckFactory:
    """Factory for creating integrity check components"""

    @staticmethod
    def create_service(rest_connector) -> MerkleTreeService:
        """Create a fully configured MerkleTreeService"""

        # Create implementations
        file_system = StandardFileSystem()
        hash_storage = RestHashStorage(rest_connector)
        time_provider = SystemTimeProvider()
        hash_function = SHA1HashFunction()

        # Create components
        path_validator = PathValidator()
        tree_walker = DirectoryTreeWalker(file_system)
        file_hasher = FileHasher(file_system, hash_function, time_provider)

        # Create main service
        return MerkleTreeService(hash_storage, tree_walker, file_hasher, path_validator)
```

## 8. Updated Main Interface

```python
# integrity_check.py
"""
Merkle Tree File Integrity System

Refactored for improved testability and maintainability.
"""

from .factory import IntegrityCheckFactory
import rest_connector

# Create the service instance
_service = IntegrityCheckFactory.create_service(rest_connector)

def DFS_merkle(root_path: str, dir_path: str):
    """
    Entry point for computing Merkle tree hash and detecting changes

    This function maintains backward compatibility with the original API
    while using the new refactored implementation.
    """
    return _service.compute_merkle_tree(root_path, dir_path)

def recompute_root(root_path: str, dir_path: str, change_dict: dict):
    """
    Legacy function for recomputing parent hashes

    Note: This functionality is now handled automatically by compute_merkle_tree
    """
    # This is now handled internally by the service
    pass

# Legacy hash function exports for backward compatibility
def get_hash_func():
    """Returns SHA-1 hash function"""
    import hashlib
    return hashlib.sha1

def perform_hash(hash_string: str) -> str:
    """Generate SHA-1 hash of input string"""
    import hashlib
    return hashlib.sha1(hash_string.encode()).hexdigest()

def get_link_hashable(link_path: str) -> str:
    """Generate hashable representation of a link"""
    from pathlib import Path
    return f"{link_path} -> {str(Path(link_path).readlink())}"

def get_dir_hashable(dir_path: str, hash_info: dict) -> str:
    """Generate hashable representation of directory contents"""
    hash_string = ''
    for category in ['dirs', 'files', 'links']:
        items = hash_info[dir_path].get(category, [])
        if items:
            for item in sorted(items):
                item_path = f"{dir_path}/{item}"
                hash_string += hash_info[item_path]['current_hash']
        else:
            hash_string += f"{dir_path}/{category}: EMPTY "
    return hash_string
```

## 9. Comprehensive Unit Tests

```python
# test_merkle_tree_service.py
import unittest
from unittest.mock import Mock, patch, mock_open
from integrity_check.merkle_tree_service import MerkleTreeService
from integrity_check.implementations import SHA1HashFunction

class TestMerkleTreeService(unittest.TestCase):
    def setUp(self):
        self.mock_hash_storage = Mock()
        self.mock_tree_walker = Mock()
        self.mock_file_hasher = Mock()
        self.mock_path_validator = Mock()

        self.service = MerkleTreeService(
            self.mock_hash_storage,
            self.mock_tree_walker,
            self.mock_file_hasher,
            self.mock_path_validator
        )

    def test_compute_merkle_tree_invalid_path(self):
        # Arrange
        self.mock_path_validator.validate_root_and_dir_paths.return_value = False

        # Act
        result = self.service.compute_merkle_tree("/root", "/invalid")

        # Assert
        self.assertEqual(result, (None, None))
        self.mock_path_validator.validate_root_and_dir_paths.assert_called_once_with("/root", "/invalid")

    def test_compute_merkle_tree_valid_path(self):
        # Arrange
        self.mock_path_validator.validate_root_and_dir_paths.return_value = True
        self.mock_tree_walker.get_tree_structure.return_value = {
            "/test": {"dirs": [], "files": ["file1.txt"], "links": []}
        }
        self.mock_file_hasher.hash_file.return_value = "file_hash_123"
        self.mock_file_hasher.hash_directory.return_value = "dir_hash_456"
        self.mock_file_hasher.get_current_timestamp.return_value = "1234567890"
        self.mock_hash_storage.put_hashtable.return_value = {
            'Created': set(), 'Deleted': set(), 'Modified': set()
        }

        # Act
        dir_hash, changes = self.service.compute_merkle_tree("/test", "/test")

        # Assert
        self.assertEqual(dir_hash, "dir_hash_456")
        self.assertIsInstance(changes, dict)
        self.assertIn('Created', changes)
        self.assertIn('Deleted', changes)
        self.assertIn('Modified', changes)

class TestFileHasher(unittest.TestCase):
    def setUp(self):
        self.mock_file_system = Mock()
        self.hash_function = SHA1HashFunction()
        self.mock_time_provider = Mock()

        from integrity_check.file_hasher import FileHasher
        self.file_hasher = FileHasher(
            self.mock_file_system,
            self.hash_function,
            self.mock_time_provider
        )

    def test_hash_file(self):
        # Arrange
        test_content = [b"hello", b"world"]
        self.mock_file_system.read_file_chunks.return_value = iter(test_content)

        # Act
        result = self.file_hasher.hash_file("/test/file.txt")

        # Assert
        expected_hash = self.hash_function.create_hasher()
        for chunk in test_content:
            expected_hash.update(chunk)
        self.assertEqual(result, expected_hash.hexdigest())

    def test_hash_link(self):
        # Arrange
        self.mock_file_system.readlink.return_value = "/target/path"

        # Act
        result = self.file_hasher.hash_link("/test/link")

        # Assert
        expected_input = "/test/link -> /target/path"
        expected_hash = self.hash_function.hash_string(expected_input)
        self.assertEqual(result, expected_hash)

class TestDirectoryTreeWalker(unittest.TestCase):
    def setUp(self):
        self.mock_file_system = Mock()

        from integrity_check.tree_walker import DirectoryTreeWalker
        self.walker = DirectoryTreeWalker(self.mock_file_system)

    def test_get_tree_structure(self):
        # Arrange
        mock_walk_result = [
            ("/test", ["subdir"], ["file1.txt", "link1"])
        ]
        self.mock_file_system.walk.return_value = mock_walk_result
        self.mock_file_system.is_file.side_effect = lambda x: "file1.txt" in x

        # Act
        result = self.walker.get_tree_structure("/test")

        # Assert
        expected = {
            "/test": {
                "dirs": ["subdir"],
                "files": ["file1.txt"],
                "links": ["link1"]
            }
        }
        self.assertEqual(result, expected)

class TestPathValidator(unittest.TestCase):
    def setUp(self):
        from integrity_check.validators import PathValidator
        self.validator = PathValidator()

    def test_validate_root_and_dir_paths_valid(self):
        # Act & Assert
        self.assertTrue(self.validator.validate_root_and_dir_paths("/root", "/root/subdir"))
        self.assertTrue(self.validator.validate_root_and_dir_paths("/root", "/root"))

    def test_validate_root_and_dir_paths_invalid(self):
        # Act & Assert
        self.assertFalse(self.validator.validate_root_and_dir_paths("/root", "/other"))

# Mock implementations for testing
class MockFileSystem:
    def __init__(self):
        self.files = {}
        self.dirs = set()
        self.links = {}

    def add_file(self, path: str, content: bytes):
        self.files[path] = content

    def add_dir(self, path: str):
        self.dirs.add(path)

    def add_link(self, path: str, target: str):
        self.links[path] = target

    def exists(self, path: str) -> bool:
        return path in self.files or path in self.dirs or path in self.links

    def is_file(self, path: str) -> bool:
        return path in self.files

    def is_dir(self, path: str) -> bool:
        return path in self.dirs

    def read_file_chunks(self, path: str, chunk_size: int = 65536):
        if path in self.files:
            content = self.files[path]
            for i in range(0, len(content), chunk_size):
                yield content[i:i + chunk_size]

    def readlink(self, path: str) -> str:
        return self.links.get(path, "")

class MockHashStorage:
    def __init__(self):
        self.storage = {}

    def put_hashtable(self, hash_info):
        self.storage.update(hash_info)
        return {'Created': set(), 'Deleted': set(), 'Modified': set()}

    def get_hashtable(self, path):
        return self.storage.get(path)

    def get_single_hash(self, path):
        item = self.storage.get(path, {})
        return item.get('current_hash')
```

## Key Benefits of This Refactoring:

1. **Separation of Concerns**: Each class has a single responsibility
2. **Dependency Injection**: All dependencies are injected, making testing easy
3. **Interface-Based Design**: Easy to mock and test individual components
4. **Backwards Compatibility**: Original API is preserved
5. **Testability**: Each component can be unit tested in isolation
6. **Maintainability**: Changes to one component don't affect others
7. **Extensibility**: New hash functions, storage backends, or file systems can be added easily

This refactored structure makes it much easier to write comprehensive unit tests for each component while maintaining the original functionality and API.